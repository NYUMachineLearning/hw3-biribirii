---
title: "Classification_hw"
author: "Brian Chang"
date: "2019/10/2"
output: html_document
---

```{r, include=FALSE}
library(caret)
library(ROCR)
library(pROC)
library(MASS)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggfortify)
library(glmnet)
library(tidyverse)
library(mlbench)
```

# Homework

## Lasso

$$Lasso Regression=\sum_{i=1}^{n}(y_i - w_0 - \sum_{j=1}^{p}w_jx_{ij})^2 + \lambda\sum_{j=1}^p|w_j|$$
2. Create and train model 
```{r}
ctrl =  trainControl(method = "boot", 15)

Lasso_regression <- train(Temp ~ Wind + Month, data = train_regression,
                          method = 'lasso', trControl= ctrl) 
```

```{r}
Lasso_regression
```

Examine the residuals 
```{r}

lasso_test_pred <- predict(Lasso_regression, newdata = test_regression)

#plot the predicted values vs the observed values
plot_lasso_test_pred <- data.frame(Temp_test_pred = lasso_test_pred, 
                                   Observed_Temp = test_regression$Temp)
ggplot(data = plot_lasso_test_pred) +
  geom_point(aes(x=Observed_Temp, y = Temp_test_pred)) + 
  ggtitle("True Temp Value vs Predicted Temp Value Lasso Regression") +
  theme_bw()

#median residual value should be close to zero
median(resid(Lasso_regression))
```


#Homework:

1. Use the Breast Cancer dataset from the mlbench package, and predict whether the cancer is malignant or benign using one of the algorithms we learned about in class. Give some rationale as to why you chose this algorithm. Plot ROC curves, and confusion matrices. If you are choosing a hyperparameter like K or lambda, explain how and why you chose it. 

```{r breastcancer}
data(BreastCancer)

BreastCancer <- na.omit(BreastCancer)

train_breastcancer <- floor(0.75 * nrow(BreastCancer))
set.seed(20)
train_pos <- sample(seq_len(nrow(BreastCancer)), size = train_breastcancer)
train_classifier <- BreastCancer[train_pos,]
test_classifier <- BreastCancer[-train_pos,]

dim(train_classifier)
dim(test_classifier)
```


## Linear Discriminant analysis

* Good for well separated classes, more stable with small n than logistic regression, and good for more than 2 response classes. 
* LDA assumes a normal distribution with a class specific mean and common variance. 

* We chose to run the LDA model on this dataset because the sample size is relatively small. Furthermore, the two classes (benign vs. malignant) appear to be well separated. However, the distributions are not normal.


```{r}
clthickness <- ggplot(data = BreastCancer, aes(x = Cl.thickness, fill = Class)) + 
  geom_bar(position="identity", alpha=0.5)  +
  theme_bw()

cellsize <- ggplot(data = BreastCancer, aes(x = Cell.size, fill = Class)) + 
  geom_bar(position="identity", alpha=0.5)  +
  theme_bw()

cellshape <- ggplot(data = BreastCancer, aes(x = Cell.shape, fill = Class)) + 
  geom_bar(position="identity", alpha=0.5)  +
  theme_bw()

margadhesion <- ggplot(data = BreastCancer, aes(x = Marg.adhesion, fill = Class)) + 
  geom_bar(position="identity", alpha=0.5)  +
  theme_bw()

epithcsize <- ggplot(data = BreastCancer, aes(x = Epith.c.size, fill = Class)) + 
  geom_bar(position="identity", alpha=0.5)  +
  theme_bw()

barenuclei <- ggplot(data = BreastCancer, aes(x = Bare.nuclei, fill = Class)) + 
  geom_bar(position="identity", alpha=0.5)  +
  theme_bw()

blcromatin <- ggplot(data = BreastCancer, aes(x = Bl.cromatin, fill = Class)) + 
  geom_bar(position="identity", alpha=0.5)  +
  theme_bw()

normalnucleoli <- ggplot(data = BreastCancer, aes(x = Normal.nucleoli, fill = Class)) + 
  geom_bar(position="identity", alpha=0.5)  +
  theme_bw()

mitoses <- ggplot(data = BreastCancer, aes(x = Mitoses, fill = Class)) + 
  geom_bar(position="identity", alpha=0.5)  +
  theme_bw()

grid.arrange(clthickness, cellsize, cellshape, margadhesion, epithcsize, barenuclei, blcromatin, normalnucleoli, mitoses)

```

 
```{r LDA}
LDA <- lda(Class ~ Cl.thickness + Cell.size + Cell.shape + Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + Normal.nucleoli + Mitoses, data= train_classifier, cv= T)
```


```{r}
LDA
```


```{r predict}
LDA_predict <- predict(LDA, newdata=test_classifier)
confusionMatrix(LDA_predict$class, reference = test_classifier$Class)
```

```{r ROC}
# save the predictions in a new variable
predictions <- as.data.frame(LDA_predict$posterior) %>% 
  rownames_to_column("idx")

test_classifier <- test_classifier %>% 
  rownames_to_column("idx")

predictions_actual <- full_join(predictions,test_classifier, by = "idx" )

# choose the two classes we want to compare, setosa and versicolor
set_vers_true_labels <- predictions_actual %>% 
  filter(Class %in% c("benign", "malignant")) %>% 
  mutate(Class = as.character(Class)) 
  
#make dataframe of the prediction and the label
pred_label <- data.frame(prediction = set_vers_true_labels$benign,
                         label = set_vers_true_labels$Class)

ggplot(pred_label, aes(x = 1:171, y = prediction, color = label))+
  geom_point()

pred <- prediction(set_vers_true_labels$setosa, set_vers_true_labels$Species, 
label.ordering = c("malignant", "benign")) 

perf <- performance(pred,"tpr","fpr")
plot(perf)
```



